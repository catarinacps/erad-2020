# -*- org-export-babel-evaluate: nil -*-
# -*- coding: utf-8 -*-
# -*- mode: org -*-

#+title: Análise da Influência do /Runtime/ OpenMP no Desempenho de Aplicação com Tarefas @@latex: \vspace{-0.2cm}@@
#+author: @@latex: \vspace{-0.1cm}@@ Henrique Corrêa Pereira da Silva@@latex:\and@@
#+author: Marcelo Cogo Milletto@@latex:\and@@
#+author: Vinicius Garcia Pinto@@latex:\and\\@@
#+author: Lucas Mello Schnorr @@latex: \vspace{-0.2cm}@@

#+begin_export latex
\address{
  \vspace{-0.2cm}
  Instituto de Informática -- Universidade Federal do Rio Grande do Sul (UFRGS)
  \email{\{hcpsilva,marcelo.miletto,vgpinto,schnorr\}@inf.ufrgs.br}
}

\maketitle
#+end_export

#+latex: \vspace{-0.5cm}

#+begin_resumo
Nesse trabalho verificamos o comportamento de cinco /runtimes/ numa
aplicação com programação baseada em tarefas. Observamos discrepâncias
na duração das tarefas em relação ao tempo total de duração
de algumas versões, além de dificuldades no gerenciamento com número
excessivo de tarefas nas versões LIBKOMP e KStar_{StarPU}. A versão
StarPU manteve bom desempenho mesmo com tarefas significativamente
mais lentas que as de outras versões.
#+end_resumo

#+latex: \vspace{-0.6cm}

* Configuração                                                     :noexport:

# Local Variables:
# eval: (require 'ox-extra)
# eval: (require 'org-inlinetask)
# eval: (ox-extras-activate '(ignore-headlines))
# eval: (setq ispell-local-dictionary "brasileiro")
# eval: (flyspell-mode t)

# End:

#+startup: overview indent
#+language: pt-br
#+options: H:3 creator:nil timestamp:nil skip:nil toc:nil num:t ~:~ date:nil title:nil
#+tags: noexport(n) deprecated(d) ignore(i)
#+export_select_tags: export
#+export_exclude_tags: noexport

#+latex_class: article
#+latex_class_options: [12pt]
#+latex_header: \usepackage{sbc-template}
#+latex_header: \usepackage[brazil]{babel}
#+latex_header: \usepackage[utf8]{inputenc}
#+latex_header: \usepackage[T1]{fontenc}
#+latex_header: \usepackage{graphicx}
#+latex_header: \usepackage[caption=false]{subfig}
#+latex_header: \usepackage{booktabs}
#+latex_header: \usepackage{hyphenat}
#+latex_header: \usepackage{breakcites}
#+latex_header: \usepackage{fancyvrb}
#+latex_header: \hyphenation{e-la-bo-ra-ção re-pre-sen-tar}

#+latex_header: \addtolength{\textfloatsep}{-0.0cm}
#+latex_header: \setlength\textfloatsep{0.0cm}
#+latex_header: \setlength\floatsep{0.0cm}
#+latex_header: \addtolength\abovecaptionskip{-0.0cm}
#+latex_header: \setlength\abovecaptionskip{-0.4cm}
#+latex_header: \addtolength\belowcaptionskip{-0.0cm}
#+latex_header: \setlength\belowcaptionskip{0.0cm}

# You need at least Org 9 and Emacs 24 to make this work.
# If you do, just type make (thanks Luka Stanisic for this).

* Introdução, Objetivos e Trabalhos Relacionados

#+begin_comment
- HPC é tri; contexto (paralelismo de tarefas)
  - Vários /runtimes/ capazes de prover esse paralelismo
  - ...
- Identificação do problema!
  - Problema: o desempenho depende do /runtime/ e não mais do programador
    - Qual é melhor /runtime/? Principalmente, porque um é melhor que outro?
  - Trabalhos relacionados
    - Marcelo
    - Outros a partir do trabalho do Marcelo
- Objetivos
  - Comparação do escalonamento
  - Análise de ociosidade
  - Observação de anomalies dependentes do /runtime/
    (Diferenças de tempo de /kernel/ em função do /runtime/)
- Constribuição
- Estrutura do artigo
#+end_comment

#+begin_comment Vinicius
Este primeiro paragráfo está bom, porém não temos tanto espaço, então o ideal
seria cortá-lo para umas 6 linhas, mantendo a mesma essencia, mas sendo mais
direto. Como a ERAD é um evento especifico de alto desempenho, podemos ser mais
diretos já que o público alvo tem algum dominio/interesse na temática.
#+end_comment

# Supercomputadores e computação de alto desempenho em geral são, hoje em dia,
# jogadores majoritariamente invisíveis num mundo cujos usuários de tecnologia
# exigem contato ubíquo e imperceptível com a informação ao alcance de suas
# mãos. Embora de sutil presença, a demanda à sistemas de alto desempenho cresce
# exponencialmente e, para alcançar essas exigências, o paralelismo se firma
# como único método confiável para prover o grau de performance desejado nesses
# sistemas. :'(

Após décadas trabalhando em sistemas e num ferramental a par da exponencial
demanda por paralelismo, nos encontramos num período no qual o desenvolvedor de
sistemas de alto desempenho tem diversas escolhas de bibliotecas, de /runtimes/
e de /APIs/ para explorar a fim de utilizar efetivamente o /hardware/ desses
sistemas. Entretanto, a diferença entre essas é tal que não se trata mais da
qualidade da implementação ditar a performance desses sistemas, mas sim a
escolha de biblioteca utilizada pelo programador. Com isso, surge a questão de
definir qual dessas é a mais performática e, sobretudo, por que ela é.

# achei sketchy até aqui
# outra realização: não tem tanto espaço assim na verdade, e ainda falta muita
# coisa!

Podemos citar OpenMP \cite{dagum1998openmp}, a partir da versão 4, e StarPU
\cite{augonnet2011starpu} como ferramentas de programação paralela que suportam
modelos mais sofisticados de paralelismo, como a programação baseada em
tarefas. Nessa, a lógica de um programa é organizada em tarefas e o paralelismo
é inferido implicitamente pelas dependências de dados entre cada uma dessas
tarefas, o que se traduz num grafo direcionado acíclico (/DAG/). Assim, o
/runtime/ em questão se assegura de escalonar e distribuir essas tarefas dentre
seus /workers/ respeitando as dependências declaradas.
# StarPU foi projetado especificamente com esse conceito em
# mente e, na versão =3.0= de sua especificação, esse conceito foi
# introduzido na especificação do OpenMP.

Avaliaremos o desempenho e comportamento de uma fatoração QR para matriz densa
com duas implementações, uma utilizando diretamente as diretivas de tarefas do
OpenMP e outra nativa em StarPU. A primeira será executada com os /runtimes/
nativos do GCC e do LLVM, o /runtime/ da biblioteca LIBKOMP baseado em X-Kaapi e
através da transpilação para StarPU via compilador KStar. Sendo assim, nossos
objetivos nesse trabalho são comparar o *escalonamento* das tarefas, observar a
*ociosidade* dos trabalhadores de cada /runtime/ e identificar *anomalias* em
quaisquer das bibliotecas avaliadas.

# lembrete pra eu colocar o paragrafo de related work aqui
#+begin_comment
Deixa sem por eqto, só vamos citar o do marcelo. Depois na versão final, fazemos
este ajuste..
#+end_comment

* Metodologia de Coleta e Análise de Dados

#+begin_comment
- Visão geral do workflow
  - Figura mostrando o funcionamento (com o texto a explicando)
#+end_comment

Nessa seção versaremos sobre a metodologia experimental, assim como o
ferramental de /software/ utilizado para a análise dos dados coletados. Além
disso, abordaremos o /workflow/ adotado a fim de aprimorar a reprodutibilidade
dos resultados aqui apresentados.

** Projeto Experimental

A fim de analisar o impacto dos diferentes /runtimes/ aqui avaliados, definimos
como fatores do projeto experimentar o tamanho da *matriz* e o tamanho do
*bloco* de cada tarefa. O tamanho do bloco varia em fatores de potências de $2$
entre $[32, 512]$, resultando, assim, em cinco níveis, enquanto o tamanho da
matriz foi fixado em $8192$. Através da combinação fatorial completa de todos
esses parâmetros de execução \cite{jain1991art}, obtivemos a acurácia necessária
para que nós observássemos a tendência do impacto do número das tarefas geradas
pela a aplicação. Cada combinação foi repetida 5 vezes para cada experimento em
cada nó para a avaliação do /makespan/ e 1 vez para a coleta do traço das
execuções.

** Manipulação de dados com ferramentas modernas de /data science/

É essencial possuir um conjunto de ferramentas atualizado e apropriado para
garantir a qualidade de quaisquer análises em qualquer estudo. Sendo assim,
compreendemos essas garantias ao empregar a linguagem R em conjunto com o pacote
tidyverse através de blocos de códigos embutidos em arquivos Org
\cite{dominik2010orgmode} versionados na ferramenta =git=. Com tal abordagem
construímos um caderno de laboratório (/labbook/) que centralizou o processo
exploratório científico, as anotações decorrentes e todos os experimentos
realizados, desde o projeto desses até o código de análise dos dados
coletados. Acreditamos que dessa maneira pode-se assegurar a reprodutibilidade e
a verificação dos resultados obtidos \cite{stanisic2015workflow} sem perder a
flexibilidade necessária para que processos de desenvolvimento e de verificação
ocorressem paralelamente.

# O que eu quis dizer com isso exatamente? "flexibilidade dos processos de
# desenvolvimento e de verificação"?
# O que eu queria dizer era que essa abordagem não enrigeceu o workflow a ponto
# do paralelismo de contribuições paralelas do git fosse perdido. Se é que isso
# faz sentido.

# sobre assegurar a reprodutibilidade: tenho alguma ideia de que é um processo
# muito mais complexo, mas me faltou palavras para afirmar que nossa segurança
# sobre a reprodutibilidade aumentou sem utilizar palavras tão fortes.

#+latex: \noindent
*Execução e Coleta dos Dados*: A automação dessas foi materializada por
/scripts/ Shell executados pelo gerenciador de /jobs/ Slurm em cada nó de
computação detalhado na [[tab:plataformas][Tabela 1]]. Dada inevitável
complexidade de dependências dos /runtimes/ aqui abordados, também desenvolvemos
um /script/ que abstrai detalhes pertinentes a plataforma do /cluster/ e permite
a fácil reprodução de um experimento numa só linha de comando.

#+latex: \noindent
*Exploração e Análise dos Dados*: A integração das ferramentas previamente
citadas no editor Emacs permitiu o uso de blocos de código de análise dos dados
em R entrelaçados com notas sobre esses. Uma abordagem similar é a dos /Jupyter
Notebooks/, que porém acaba mais restrita pelo versionamento mais limitado dos
arquivos em /rich text/.

# essa última frase está especialmente fraca

#+latex: \noindent
*Visualização e Concepção do Artigo*: Após análise das observações, as
visualizações dessas constavam também nos mesmos blocos de código de análise
embutidos no /labbook/. Com a criação das visualizações, utilizamos um arquivo
Org secundário para escrever o artigo e exportá-lo para LaTeX através do sistema
de exportação da ferramenta.

# acredito que é possível perceber que eu não sei mais o que falar sobre o
# workflow.

* Resultados Experimentais e Observações

Nessa seção apresentaremos, com auxilio de visualizadões, os fenômenos observados na
experimentação. Além disso, detalharemos as plataformas utilizadas.

#+begin_comment
\noindent
*Configuração Experimental*:
- Configuração de SW e HW
  - Detalhamentos precisos (versão, cores, modelo da CPU, Qtdade memória)
- SW
  - Starpu/LWS
#+end_comment

#+name: tab:plataformas
#+attr_latex: :float t :placement [!htb] :font \small
#+caption: Configuração das plataformas utilizadas nos experimentos.
|---------+-----------+---------------------------------------+--------------------+------------|
| <l>     | <l>       | <l>                                   | <l>                | <l>        |
| *Nome*  | *#_{1,2}* | *CPU*                                 | *L1/L2/LLC*        | *RAM*      |
|---------+-----------+---------------------------------------+--------------------+------------|
| =draco= | $5, 1$    | $2 \times 8$ Xeon E5 2640 v2 2.5GHz   | 32KB/256KB/20MB    | 64GB DDR3  |
| =cei=   | $7, 1$    | $2 \times 12$ Xeon Silver 4116 2.1GHz | 32KB/1024KB/16.5MB | 93GB DDR4  |
| =hype=  | $4, 1$    | $2 \times 10$ Xeon E5 2650 v3 2.3GHz  | 32KB/256KB/25MB    | 128GB DDR4 |
|---------+-----------+---------------------------------------+--------------------+------------|

#+latex: \noindent
*Configuração Experimental*: Na execução da aplicação, usamos as plataformas
descritas na [[tab:plataformas][Tabela 1]] e as ferramentas da
[[tab:versoes][Tabela 2]]. Todas executam Debian (=10.2=) com /kernel/ Linux
=4.19.0-6=.

#+begin_comment
Listamos em cada uma dessas o seu identificador, a quantidade de nós utilizados
na coleta do /makespan/ e do rastreamento, o(s) processador(es), a quantidade e
níveis de memória /cache/ e quantidade de memória /RAM/, respectivamente.

A versão da distribuição corresponde ao lançamento da segunda atualização da
décima distribuição estável =10.2=, de codinome Buster.
#+end_comment

#+name: tab:versoes
#+attr_latex: :float t :placement [!htb] :font \small
#+caption: Características das versões executadas da aplicação.
|-------------------+-----------+--------------------------+-------------------------------------|
| <l>               | <l>       | <l>                      | <l>                                 |
| *Identificador*   | *Fonte*   | *ABI/API Utilizada*      | *Versão*                            |
|-------------------+-----------+--------------------------+-------------------------------------|
| libgomp_{GCC}     |           | OpenMP/GCC               | =8.3.0=                             |
| libomp_{LLVM}     |           | OpenMP/LLVM              | =6.0.0=                             |
| KStar_{StarPU}    | Diretivas | StarPU (/LWS scheduler/) | =master=\xfeff_{=bf6af54e57bad130=} |
| LIBKOMP_{libgomp} |           | OpenMP/LIBKOMP-LLVM      | =master=\xfeff_{=32781b6dab10b1b5=} |
| LIBKOMP_{libomp}  |           | OpenMP/LIBKOMP-GCC       | =master=\xfeff_{=32781b6dab10b1b5=} |
|-------------------+-----------+--------------------------+-------------------------------------|
| StarPU            | Nativo    | StarPU (/LWS scheduler/) | =1.3.1=                             |
|-------------------+-----------+--------------------------+-------------------------------------|

#+begin_comment
*Versão das Bibliotecas e Binários*: A ferramenta utilizada para a compilação de
todos os binários foi o /frontend/ para a linguagem C do sistema de compiladores
GCC, versão =8.3.0= \cite{gnu2018manual}. As bibliotecas padrão utilizadas
foram, portanto, as distribuídas com esse /release/ do compilador. O /runtime/
de OpenMP utilizado do projeto LLVM foi a versão distribuída com o lançamento
=6.0.0= do /frontend/ Clang \cite{llvm2018manual}. Todas os /runtimes/ de OpenMP
utilizados seguem a especificação =4.5= \cite{openmp2015spec}. A versão da
biblioteca StarPU utilizada foi a versão estável =1.3.1= utilizando o
/scheduler/ padrão /Locality Work Stealing/ (/LWS/). Para todos os binários
gerados, utilizamos a biblioteca LAPACK \cite{lapack1999guide} de versão
=3.8.0=, distribuída no pacote Netlib[fn:2]. Para as ferramentas LIBKOMP
\cite{broquedis2012libkomp} e KStar \cite{agullo2017kstar}, foram utilizadas as
versões em desenvolvimento das /branches/ =libkomp= (/commit hash/
=32781b6dab10b1b5=) e =master= (/commit hash/ =bf6af54e57bad130=)
respectivamente.
#+end_comment

O rastreamento da aplicação utilizando a biblioteca libgomp_{GCC} foi realizado
utilizando a ferramente ScoreP =6.0= e, quando utilizando a biblioteca
libomp_{LLVM}, rastreamos a aplicação com uma biblioteca própria utilizando
chamadas conforme a especificação OMPT =4.5=. O rastreamento das biblioteca e
compilador StarPU e KStar_{StarPU} foi realizado através da biblioteca FxT
=0.3.5= e o rastreamento das versões utilizando LIBKOMP foi realizado pelo
próprio /runtime/, que implementa chamadas à /API/ OMPT.

# [fn:1] O link para o /website/ da distribuição é: https://www.debian.org/
# [fn:2] O link para o /website/ do Netlib é: https://www.netlib.org/

#+latex: \noindent
*Diferenças de tempo de execução dos /kernels/ em função do /runtime/*:
Executamos as versões das aplicações descritas na [[tab:versoes][Tabela 2]]
coletando os tempos de execução que são apresentados nos gráficos da
[[fig:makespan][Figura 1]]. Nas colunas observamos os diferentes tamanhos de
bloco de cada tarefa e na linhas observamos as diferentes máquinas utilizadas no
experimento. Apresentamos ambas média das 5 observações e seu erro padrão.

#+name: fig:makespan
#+attr_latex: :float t :placement [!htb]
#+caption: Comparação do /makespan/ da execução de cada runtime.
[[../img/makespan-all.png]]

Observamos que a tendência de comportamento se preserva entre as plataformas
utilizadas. Sendo assim, analisaremos nas próximas seções os detalhes da
execução das tarefas na plataforma =cei= com o tamanho $64$ de bloco.

#+latex: \noindent
*Análise de Ociosidade por /Worker/*: Na [[fig:idleness][Figura 2]] observamos
que, além do caso de tamanho $64$, os /runtimes/ mantém ociosidade similar para
todos os casos. Com um tamanho de bloco $64$ os /runtimes/ necessitam lidar com
um grande número de tarefas, o que estressa a capacidade de escalonamento, o
que, por consequência, afeta na quantidade de tempo ocioso por /worker/ da
plataforma.

#+name: fig:idleness
#+attr_latex: :float t :placement [!htb]
#+caption: Comparação do /idleness/ das tarefas em cada runtime e /worker/.
[[../img/idleness-all-cei.png]]

Pela análise da figura, observamos que esse caso é especialmente interessante,
já que ambos LIBKOMP_clang quanto KStar_{StarPU} apresentam ociosidade média
significativamente alta. Em todos os casos, libgomp_{GCC}, libomp_{LLVM} e
StarPU mantém performance compatível em questão da efetividade do escalonamento
das tarefas.

#+begin_comment
Figura que a gente conversou
- cowplot -> ~plot_grid~, alinhamento do eixo X (tempo), eixo Y são os workers
- Selecionar alguns dgeqrt (primeira tarefa de cada laço mais externo)
  - Colocar elas em evidência de maneira sincronizado
#+end_comment

#+latex: \noindent
*Comparação do Escalonamento entre os três /runtimes/*: A [[fig:dgeqrt][Figura
3]] apresenta o tempo de início da tarefa =dgeqrt=, que é o primeiro
procedimento realizado no laço de execução de uma fatoração QR. Ao observar este
tempo, esperamos verificar a progressão da implementação no processo de
fatoração e a eficiência desse.

#+name: fig:dgeqrt
#+attr_latex: :float t :placement [!htb]
#+caption: Comparação do escalonamento e progressão de cada /runtime/
[[../img/dgeqrt-start-cei.png]]

#+latex: \vspace{-0.5cm}

Fora as implementações KStar_{StarPU} e StarPU, todas essas tarefas foram
iniciadas no primeiro segundo de execução. Além disso, a implementação
KStar_{StarPU} iniciou essas tarefas significativamente antes do que a em StarPU
nativo.

* Conclusão e Trabalhos Futuros

#+begin_comment
Precisamos aprofundar a investigação

suposicoes:
- kstar parece nao estar respeitando as deps (faz sentido pelo
makespan mto curto e pela figura "schnorr")
  - solucoes? implementar a verificacao da solucao
  - olhar as dependencias das tarefas (starpu e kstar possuem essa
  info)
- kstar e libkomp nao sao bons com grão pequeno (mtas tarefas) ->
conforme podemos ver nos gráficos de idleness

- daqui pra baixo, foco no tamanho 64 que no momento é o mais
intrigante!!

- tarefas no kstar e starpu sao mto mais lentas sem razao aparente
  - embora starpu tenha bom desempenho

- tarefas starpu duram mto mais, os tempos sao compativeis
  - quem está errado, rastreamento do starpu ou os demais?

  - continuar a analise dos rastros, visualmente sao compativeis, mas
  é inconsistente com a duração das tarefas (ver cei tamanho 64)
    - contar se o número de tarefas bate (tem q bater)
      - suposicao: A minha suposição é o rastreamento do marcelo e/ou
      scorep esta fatiando algumas tarefas
      - como proovar (isso só pra dois runtimes starpu vs ompt) :
        - plotar total de tarefas de cada tipo em cada runtime.
        - soma o tempo total gasto computando cada tarefa

- trabalhos futuros:
  continuar a analise, implementar a verificacao da solucao do qr,
  incluir ompss, testar outras arquiteturas (cpu)
#+end_comment

Nesse trabalho analisamos o desempenho e comportamento de cinco /runtimes/
implementando uma fatoração QR utilizando tarefas. A partir dessas observações,
identificamos que os tempos de duração das tarefas são incompatíveis com a taxa
de ociosidade e tempo total observados, como é o caso das implementações
libgomp_{GCC}, libomp_{LLVM} e LIBKOMP. Além disso, verificamos que as
ferramentas KStar e LIBKOMP não obtiveram desem desejável quando o grão de
trabalho era pequeno, conforme detalhado na [[/Análise de Ociosidade por
/Worker/][Subseção 3.3]]. Pela visualização do /makespan/ da
[[fig:makespan][Figura 1]] percebemos que existe um comportamento anômalo da
ferramenta KStar_{StarPU} em quase todos os casos, o que acreditamos indicar que
esta versão não está respeitando as dependências de dados entre as tarefas.

Tais constatações pedem pela continuação e aprofundamento da investigação até
aqui realizada. Para trabalhos futuros, consideramos implementar a verificação
da solução obtida pela execução, adicionar o /runtime/ OmpSs
\cite{duran2011ompss} aos testes e também abranger diferentes arquiteturas de
processador nos testes.

* Referências                                                        :ignore:

# See next section to understand how refs.bib file is created.

#+latex: \bibliographystyle{sbc}
#+latex: \bibliography{refs}

* Bibtex                                                           :noexport:

Tangle this file with C-c C-v t

#+begin_src bibtex :tangle refs.bib
% Only BIBTEX entries here

@article{agullo2017kstar,
 author = {E. {Agullo} and O. {Aumage} and B. {Bramas} and O. {Coulaud} and S. {Pitoiset}},
 journal = {IEEE Transactions on Parallel and Distributed Systems},
 title = {Bridging the Gap Between OpenMP and Task-Based Runtime Systems for the Fast Multipole Method},
 year = {2017},
 volume = {28},
 number = {10},
 pages = {2794-2807},
 doi = {10.1109/TPDS.2017.2697857},
 ISSN = {2161-9883},
 month = {Oct}
}

@inproceedings{yoo2003slurm,
 author = {Yoo, Andy B. and Jette, Morris A. and Grondona, Mark},
 title = {SLURM: Simple Linux Utility for Resource Management},
 booktitle = {Job Scheduling Strategies for Parallel Processing},
 year = {2003},
 publisher = {Springer Berlin Heidelberg},
 address = {Berlin, Heidelberg},
 pages = {44--60},
 isbn = {978-3-540-39727-4}
}

@inproceedings{broquedis2012libkomp,
 author = {Broquedis, Fran{\c{c}}ois and Gautier, Thierry and Danjean, Vincent},
 editor = {Chapman, Barbara M. and Massaioli, Federico and M{\"u}ller, Matthias S. and Rorro, Marco},
 title = {libKOMP, an Efficient OpenMP Runtime System for Both Fork-Join and Data Flow Paradigms},
 booktitle = {OpenMP in a Heterogeneous World},
 year = {2012},
 publisher = {Springer Berlin Heidelberg},
 address = {Berlin, Heidelberg},
 pages = {102--115},
 isbn = {978-3-642-30961-8}
}

@inproceedings{nesi2019pcad,
 author = {Lucas Leandro Nesi and Matheus S. Serpa and Lucas Mello Schnorr and Philippe Olivier Alexandre Navaux},
 title = {HPC Resources Management Infraestruture Description and 10-month Statistics},
 booktitle = {Anais do XVII Workshop de Processamento Paralelo e Distribuído},
 location = {Porto Alegre},
 year = {2019},
 keywords = {},
 pages = {21--24},
 url = {https://www.inf.ufrgs.br/gppd/wsppd/2019/papers/proceedings/WSPPDProceedings.pdf}
}

@inproceedings{miletto2019abrest,
 author = {Marcelo Miletto and Lucas Schnorr},
 title = {OpenMP and StarPU Abreast: the Impact of Runtime in Task-Based Block QR Factorization Performance},
 booktitle = {Anais do XX Simpósio em Sistemas Computacionais de Alto Desempenho},
 location = {Campo Grande},
 year = {2019},
 keywords = {},
 pages = {25--36},
 publisher = {SBC},
 address = {Porto Alegre, RS, Brasil},
 doi = {10.5753/wscad.2019.8654},
 url = {https://sol.sbc.org.br/index.php/wscad/article/view/8654}
}

@article{pinto2018ccpe,
 author = {Garcia Pinto, Vinícius and Mello Schnorr, Lucas and Stanisic, Luka and Legrand, Arnaud and Thibault, Samuel and Danjean, Vincent},
 title = {A visual performance analysis framework for task-based parallel applications running on hybrid clusters},
 journal = {Concurrency and Computation: Practice and Experience},
 volume = {30},
 number = {18},
 pages = {e4472},
 keywords = {Cholesky, heterogeneous platforms, high-performance computing, task-based applications, trace visualization},
 doi = {10.1002/cpe.4472},
 url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4472},
 eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.4472},
 note = {e4472 cpe.4472},
 year = {2018}
}

@article{augonnet2011starpu,
 author = {Augonnet, Cédric and Thibault, Samuel and Namyst, Raymond and Wacrenier, Pierre-André},
 title = {{StarPU}: a unified platform for task scheduling on heterogeneous multicore architectures},
 journal = {Concurrency and Computation: Practice and Experience},
 volume = {23},
 number = {2},
 pages = {187-198},
 keywords = {GPU, multicore, accelerator, scheduling, runtime system},
 doi = {10.1002/cpe.1631},
 url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.1631},
 eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.1631},
 year = {2011}
}

@article{stanisic2015workflow,
 author = {Stanisic, Luka and Legrand, Arnaud and Danjean, Vincent},
 title = {An Effective Git And Org-Mode Based Workflow For Reproducible Research},
 journal = {SIGOPS Oper. Syst. Rev.},
 issue_date = {January 2015},
 volume = {49},
 number = {1},
 month = jan,
 year = {2015},
 issn = {0163-5980},
 pages = {61--70},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2723872.2723881},
 doi = {10.1145/2723872.2723881},
 acmid = {2723881},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{knuth1984literate,
 author = {Knuth, D. E.},
 doi = {10.1093/comjnl/27.2.97},
 issn = {0010-4620},
 journal = {The Computer Journal},
 month = 2,
 number = 2,
 pages = {97--111},
 publisher = {Oxford University Press},
 title = {{Literate Programming}},
 volume = 27,
 year = 1984
}

@book{jain1991art,
 location = {New York},
 edition = {1st},
 title = {The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling},
 isbn = {978-0-471-50336-1},
 shorttitle = {The Art of Computer Systems Performance Analysis},
 abstract = {The Art of Computer Systems Performance Analysis "At last, a welcome and needed text for computer professionals who require practical, ready-to-apply techniques for performance analysis. Highly recommended!" -Dr. Leonard Kleinrock University of California, Los Angeles "An entirely refreshing text which has just the right mixture of theory and real world practice. The book is ideal for both classroom instruction and self-study." -Dr. Raymond L. Pickholtz President, {IEEE} Communications Society "An extraordinarily comprehensive treatment of both theoretical and practical issues." -Dr. Jeffrey P. Buzen Internationally recognized performance analysis expert ". it is the most thorough book available to date" -Dr. Erol Gelenbe Université René Descartes, Paris ". an extraordinary book.. A worthy addition to the bookshelf of any practicing computer or communications engineer" -Dr. Vinton G. Cer??? Chairman, {ACM} {SIGCOMM} "This is an unusual object, a textbook that one wants to sit down and peruse. The prose is clear and fluent, but more important, it is witty." -Allison Mankin The Mitre Washington Networking Center Newsletter},
 pagetotal = {685},
 publisher = {Wiley},
 author = {Jain, Raj},
 year = {1991},
 date = {1991-04}
}

@book{dominik2010orgmode,
 author = {Dominik, Carsten},
 title = {The Org Mode 7 Reference Manual - Organize Your Life with GNU Emacs},
 year = {2010},
 isbn = {1906966087, 9781906966089},
 publisher = {Network Theory Ltd.},
}

@book{stallman2017emacs,
 address = {Boston, USA},
 author = {Richard Stallman and others},
 edition = 17,
 pages = 635,
 publisher = {Free Software Foundation},
 title = {{GNU Emacs Manual}},
 url = {https://www.gnu.org/software/emacs/manual/pdf/emacs.pdf},
 urldate = {2017-12-04},
 year = 2017
}

@manual{rteam2018manual,
 title = {R: A Language and Environment for Statistical Computing},
 author = {{R Core Team}},
 organization = {R Foundation for Statistical Computing},
 address = {Vienna, Austria},
 year = {2018},
 url = {https://www.R-project.org/},
}

@article{wickham2019tidyverse,
 title = {Welcome to the {tidyverse}},
 author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
 year = {2019},
 journal = {Journal of Open Source Software},
 volume = {4},
 number = {43},
 pages = {1686},
 doi = {10.21105/joss.01686},
}

@inproceedings{gamblin2015spack,
 title = {The Spack package manager: Bringing order to HPC software chaos},
 author = {Gamblin, Todd and LeGendre, Matthew and Collette, Michael R and Lee, Gregory L and Moody, Adam and de Supinski, Bronis R and Futral, Scott},
 booktitle = {High Performance Computing, Networking, Storage and Analysis, 2015 SC-International Conference for},
 pages = {1--12},
 year = {2015},
 organization = {IEEE}
}

@inproceedings{knupfer2012scorep,
 author = {Kn{\"u}pfer, Andreas and R{\"o}ssel, Christian and Mey, Dieter an and Biersdorff, Scott and Diethelm, Kai and Eschweiler, Dominic and Geimer, Markus and Gerndt, Michael and Lorenz, Daniel and Malony, Allen and Nagel, Wolfgang E. and Oleynik, Yury and Philippen, Peter and Saviankou, Pavel and Schmidl, Dirk and Shende, Sameer and Tsch{\"u}ter, Ronny and Wagner, Michael and Wesarg, Bert and Wolf, Felix},
 editor = {Brunst, Holger and M{\"u}ller, Matthias S. and Nagel, Wolfgang E. and Resch, Michael M.},
 title = {Score-P: A Joint Performance Measurement Run-Time Infrastructure for Periscope,Scalasca, TAU, and Vampir},
 booktitle = {Tools for High Performance Computing 2011},
 year = {2012},
 publisher = {Springer Berlin Heidelberg},
 address = {Berlin, Heidelberg},
 pages = {79--91},
 isbn = {978-3-642-31476-6}
}

@book{lapack1999guide,
 author = {Anderson, E. and Bai, Z. and Bischof, C. and Blackford, S. and Demmel, J. and Dongarra, J. and Du Croz, J. and Greenbaum, A. and Hammarling, S. and McKenney, A. and Sorensen, D.},
 title = {{LAPACK} Users' Guide},
 edition = {Third},
 publisher = {Society for Industrial and Applied Mathematics},
 year = {1999},
 address = {Philadelphia, PA},
 isbn = {0-89871-447-8 (paperback)}
}

@article{dagum1998openmp,
 author = {Dagum, Leonardo and Menon, Ramesh},
 journal = {Computational Science \& Engineering, IEEE},
 number = {1},
 pages = {46--55},
 publisher = {IEEE},
 title = {{OpenMP}: an industry standard API for shared-memory programming},
 volume = {5},
 year = {1998}
}

@misc{openmp2015spec,
 author = {{OpenMP Architecture Review Board}},
 title = {{OpenMP} Application Program Interface Version 4.5},
 month = {November},
 year = {2015},
 url = {https://www.openmp.org/wp-content/uploads/openmp-4.5.pdf}
}

@manual{llvm2018manual,
 title = {Clang: a C language family frontend for LLVM Version 6.0.0},
 author = {{LLVM Developer Team}},
 organization = {LLVM Foundation},
 address = {California, United States of America},
 year = {2018},
 url = {https://releases.llvm.org/6.0.0/tools/clang/docs/UsersManual.html},
}

@manual{gnu2018manual,
 title = {{GCC}, the GNU Compiler Collection Version 8.3.0},
 author = {{GCC Team}},
 organization = {Free Software Foundation},
 address = {Massachusetts, United States of America},
 year = {2018},
 url = {https://gcc.gnu.org/onlinedocs/gcc-8.3.0/gcc/},
}

@article{blumofe1996cilk,
 title = {Cilk: An efficient multithreaded runtime system},
 author = {Blumofe, Robert D and Joerg, Christopher F and Kuszmaul, Bradley C and Leiserson, Charles E and Randall, Keith H and Zhou, Yuli},
 journal = {Journal of parallel and distributed computing},
 volume = {37},
 number = {1},
 pages = {55--69},
 year = {1996},
 publisher = {Elsevier}
}

@inproceedings{eichenberger2013ompt,
 title = {{OMPT}: An {OpenMP} tools application programming interface for performance analysis},
 author = {Eichenberger, Alexandre E and Mellor-Crummey, John and Schulz, Martin and Wong, Michael and Copty, Nawal and Dietrich, Robert and Liu, Xu and Loh, Eugene and Lorenz, Daniel},
 booktitle = {International Workshop on OpenMP},
 pages = {171--185},
 year = {2013},
 organization = {Springer}
}

@article{pheatt2008tbb,
 title = {Intel® threading building blocks},
 volume = {23},
 issn = {1937-4771},
 pages = {298},
 number = {4},
 journaltitle = {Journal of Computing Sciences in Colleges},
 shortjournal = {J. Comput. Sci. Coll.},
 author = {Pheatt, Chuck},
 date = {2008-04-01},
 year = {2008}
}

@article{duran2011ompss,
 title = {{OmpSs}: a Proposal for Programming Heterogeneous Multi-Core Architectures.},
 volume = {21},
 doi = {10.1142/S0129626411000151},
 shorttitle = {Ompss},
 pages = {173--193},
 journaltitle = {Parallel Processing Letters},
 shortjournal = {Parallel Processing Letters},
 author = {Duran, Alejandro and Ayguadé, Eduard and Badia, Rosa M. and Labarta, Jesús and Martinell, Luis and Martorell, Xavier and Planas, Judit},
 date = {2011-06-01},
 year = {2011}
}
#+end_src
